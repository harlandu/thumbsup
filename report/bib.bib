@inproceedings{naivebayes,
    author = {Rish, Irina},
    booktitle = {IJCAI-01 workshop on "Empirical Methods in AI"},
    citeulike-article-id = 352583,
    citeulike-linkout-0 = {http://www.intellektik.informatik.tu-darmstadt.de/~tom/IJCAI01/Rish.pdf},
    keywords = {bayesian, naive-bayes},
    posted-at = {2005-10-17 10:23:25},
    priority = 2,
    title = {{An empirical study of the naive Bayes classifier}},
    url = {http://www.intellektik.informatik.tu-darmstadt.de/~tom/IJCAI01/Rish.pdf},
    year = 2001
}

@article{DoddsANEWPaper,
    abstract = {{Abstract\&nbsp;\&nbsp;The importance of quantifying the nature and intensity of emotional states at the level of populations is evident: we would like to know how, when, and why individuals feel as they do if we wish, for example, to better construct public policy, build more successful organizations, and, from a scientific perspective, more fully understand economic and social phenomena. Here, by incorporating direct human assessment of words, we quantify happiness levels on a continuous scale for a diverse set of large-scale texts: song titles and lyrics, weblogs, and State of the Union addresses. Our method is transparent, improvable, capable of rapidly processing Web-scale texts, and moves beyond approaches based on coarse categorization. Among a number of observations, we find that the happiness of song lyrics trends downward from the 1960s to the mid 1990s while remaining stable within genres, and that the happiness of blogs has steadily increased from 2005 to 2009, exhibiting a striking rise and fall with blogger age and distance from the Earth's equator.}},
    author = {Dodds, Peter and Danforth, Christopher},
    citeulike-article-id = 5304694,
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10902-009-9150-9},
    citeulike-linkout-1 = {http://www.springerlink.com/content/757723154j4w726k},
    day = 17,
    doi = {10.1007/s10902-009-9150-9},
    issn = {1389-4978},
    journal = {Journal of Happiness Studies},
    keywords = {blogs, emotion, happiness},
    month = {July},
    posted-at = {2009-07-30 16:56:38},
    priority = 2,
    title = {{Measuring the Happiness of Large-Scale Written Expression: Songs, Blogs, and Presidents}},
    url = {http://dx.doi.org/10.1007/s10902-009-9150-9},
    year = 2009
}

@inproceedings{PangSentimentClassification,
 author = {Pang, Bo and Lee, Lillian and Vaithyanathan, Shivakumar},
 title = {Thumbs up?: sentiment classification using machine learning techniques},
 booktitle = {Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10},
 series = {EMNLP '02},
 year = 2002,
 pages = {79--86},
 numpages = 8,
 url = {http://dx.doi.org/10.3115/1118693.1118704},
 doi = {http://dx.doi.org/10.3115/1118693.1118704},
 acmid = 1118704,
 publisher = {Association for Computational Linguistics},
 address = {Morristown, NJ, USA},
} 

@article{JennLearnDiffDomains,
    abstract = {{Abstract\&nbsp;\&nbsp;Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. Often, however, we have plentiful labeled training data from a source domain but wish to learn a classifier which performs well on a target domain with a different distribution and little or no labeled training data. In this work we investigate two questions. First, under what conditions can a classifier trained from source data be expected to perform well on target data? Second, given a small amount of labeled target data, how should we combine it during training with the large amount of labeled source data to achieve the lowest target error at test time? We address the first question by bounding a classifier's target error in terms of its source error and the divergence between the two domains. We give a classifier-induced divergence measure that can be estimated from finite, unlabeled samples from the domains. Under the assumption that there exists some hypothesis that performs well in both domains, we show that this quantity together with the empirical source error characterize the target error of a source-trained classifier. We answer the second question by bounding the target error of a model which minimizes a convex combination of the empirical source and target errors. Previous theoretical work has considered minimizing just the source error, just the target error, or weighting instances from the two domains equally. We show how to choose the optimal combination of source and target error as a function of the divergence, the sample sizes of both domains, and the complexity of the hypothesis class. The resulting bound generalizes the previously studied cases and is always at least as tight as a bound which considers minimizing only the target error or an equal weighting of source and target errors.}},
    author = {Ben-David, Shai and Blitzer, John and Crammer, Koby and Kulesza, Alex and Pereira, Fernando and Vaughan, Jennifer},
    citeulike-article-id = 6008922,
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10994-009-5152-4},
    citeulike-linkout-1 = {http://www.springerlink.com/content/q6qk230685577n52},
    doi = {10.1007/s10994-009-5152-4},
    journal = {Machine Learning},
    posted-at = {2010-09-19 09:15:07},
    priority = 2,
    title = {{A theory of learning from different domains}},
    url = {http://dx.doi.org/10.1007/s10994-009-5152-4}
}

@article{weka,
 author = {Hall, Mark and Frank, Eibe and Holmes, Geoffrey and Pfahringer, Bernhard and Reutemann, Peter and Witten, Ian H.},
 title = {The WEKA data mining software: an update},
 journal = {SIGKDD Explor. Newsl.},
 volume = 11,
 issue = 1,
 month = {November},
 year = 2009,
 issn = {1931-0145},
 pages = {10--18},
 numpages = 9,
 url = {http://doi.acm.org/10.1145/1656274.1656278},
 doi = {http://doi.acm.org/10.1145/1656274.1656278},
 acmid = 1656278,
 publisher = {ACM},
 address = {New York, NY, USA},
}


@electronic{adaboost,
    abstract = {{Boosting is a general method for improving the accuracy of any given  learning algorithm. Focusing primarily on the AdaBoost algorithm, this  chapter overviews some of the recent work on boosting including analyses  of AdaBoost\&\#039;s training error and generalization error; boosting\&\#039;s connection  to game theory and linear programming; the relationship between boosting  and logistic regression; extensions of AdaBoost for multiclass classification  problems; methods of incorporating human knowledge into boosting; and  experimental and applied work using boosting.}},
    author = {Schapire, Robert E.},
    citeulike-article-id = {3156284},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.5565},
    keywords = {boosting, machinelearning},
    posted-at = {2009-09-30 17:20:01},
    priority = {2},
    title = {{The Boosting Approach to Machine Learning: An Overview}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.5565},
    year = {2002}
}

@MISC{adaboost2,
    author = {Yoav Freund and Robert E. Schapire},
    title = {A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting},
    year = {1995}
}